{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wSwJnsjx5P"
      },
      "source": [
        "# Mnist classification with NNs\n",
        "A first example of a simple Neural Network, applied to a well known dataset.from tensorflow.keras.layers import Input, Dense\n",
        "tensorflow.keras.layers TensorFlow 的 Keras API 提供的神经网络层模块。\n",
        "Input 用于定义神经网络的输入层，指定输入数据的形状。\n",
        "Dense 全连接密集层，是神经网络中常用的一种层，所有神经元相互连接。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wMZ2Ge6jw1E"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDiNppLVkvqd"
      },
      "source": [
        "Let us load the mnist dataset\n",
        "\n",
        "tensorflow.keras.datasets：Keras 提供的一些常见数据集。\n",
        "mnist：手写数字识别数据集（28x28 像素的灰度图片，0-9 这 10 个类别）。\n",
        "\n",
        "x_train：训练集的图像数据，形状 (60000, 28, 28)，代表 60,000 张 28×28 的灰度图片。\n",
        "y_train：训练集的标签数据，形状 (60000,)，代表 60,000 个标签（每个是 0-9 之间的整数，表示手写数字的类别）。\n",
        "x_test：测试集的图像数据，形状 (10000, 28, 28)，代表 10,000 张 28×28 的灰度图片。\n",
        "y_test：测试集的标签数据，形状 (10000,)，代表 10,000 个标签（0-9 之间的整数）。\n",
        "\n",
        "x_train 和 x_test 是 3D NumPy 数组，格式：(样本数量, 高度, 宽度)。\n",
        "y_train 和 y_test 是 1D NumPy 数组，格式：(样本数量,)，每个值是 0-9 之间的整数，表示数字类别"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL8GyC0Nk14o"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijhDuLwwlQrI",
        "outputId": "e46f54d3-7f20-443e-b5d6-4d5c31c892d8"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(\"pixel range is [{},{}]\".format(np.min(x_train),np.max(x_train)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "pixel range is [0,255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01L64YcnWO5"
      },
      "source": [
        "[link text](https://)We normalize the input in the range [0,1]\n",
        "\n",
        "将像素值归一化到 [0, 1] 之间，提高模型训练效果。\n",
        "MNIST 数据集的像素值范围是 0-255，即 灰度图像的像素值范围。\n",
        "astype('float32') 转换数据类型，避免整数运算导致的精度问题。\n",
        "为什么要这么做？\n",
        "深度学习模型对数值范围较敏感：\n",
        "像素值如果保持 0-255，可能导致较大的梯度变化，影响模型训练的稳定性。\n",
        "归一化到 [0, 1]，能让模型更容易学习。\n",
        "避免溢出问题：\n",
        "深度学习中的计算涉及大量的矩阵运算，如果不归一化，容易导致梯度爆炸或消失。\n",
        "例如，计算 exp(x)（如 softmax 层）时，过大的输入可能导致数值溢出。\n",
        "\n",
        "将 28×28 的二维图像数据转换成 1D 向量（784** 维度）**，方便输入 Dense 层。\n",
        "为什么要这么做？\n",
        "全连接层 (Dense) 只能接受 1D 输入：\n",
        "Dense 层输入的数据需要是一维向量，而 x_train 的原始形状是 (60000, 28, 28)（3D）。\n",
        "reshape(60000, 28*28) 变成 (60000, 784)，每张图片变成长度为 784 的向量，适合 Dense 层。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8uA2Kp7mG9s"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = np.reshape(x_train,(60000,28*28))\n",
        "x_test = np.reshape(x_test,(10000,28*28))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\The output of the network will be a proability distribution over the different categories. Similarly, we generate a ground truth distribution, and the training objective will consist in minimizing their distance (categorical crossentropy). The ground truth distribution is the so called \"categorical\" distribution: if x has label l, the corresponding categorical distribution has probaility 1 for the category l, and 0 for all the others.\n",
        "\n",
        "适配神经网络的输出层（Softmax）\n",
        "使用交叉熵损失函数（Categorical Crossentropy）\n",
        "避免整数标签影响学习效果\n",
        "提高计算效率\n",
        "\n",
        "问题 1：神经网络会误解整数之间的“大小关系”\n",
        "如果 y_train 直接用整数表示（如 0-9），模型可能会误解类别之间的关系。\n",
        "\n",
        "问题 2：Softmax 输出层需要 One-Hot 形式\n",
        "通常，分类模型的最后一层是 softmax 层：\n",
        "\n",
        "问题 3：交叉熵损失函数需要 One-Hot\n",
        "在分类任务中，我们通常使用交叉熵损失函数（categorical_crossentropy）：\n",
        "\n",
        " 什么时候可以不用 One-Hot？\n",
        "如果你的输出层使用 sparse_categorical_crossentropy，你不需要 One-Hot 编码：\n",
        "\n",
        "这种损失函数适用于整数标签（y_train 仍然是 0-9）。\n",
        "适用于大类别分类任务（如 1000 个类别的 ImageNet）。\n",
        "但在普通分类任务（如 MNIST）中，One-Hot 编码更常用。\n",
        "\n"
      ],
      "metadata": {
        "id": "Yjrzmhgh3TZv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzWUm0UnODb",
        "outputId": "ee0c71bb-108a-4327-974b-9280af4d0215"
      },
      "source": [
        "print(y_train[0])\n",
        "y_train_cat = utils.to_categorical(y_train)\n",
        "print(y_train_cat[0])\n",
        "y_test_cat = utils.to_categorical(y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfeZF3bUrFZf"
      },
      "source": [
        "Our first Netwok just implements logistic regression\n",
        "\n",
        "Input(shape=(784,)) 定义输入张量（Tensor）。\n",
        "Dense(64, activation='relu')(input_layer) 创建权重 W 和偏置 b，并应用 ReLU 激活函数。\n",
        "Model(inputs, outputs) 组合这些层，形成完整的计算图。\n",
        "\n",
        "Input() 定义输入层，用于指定输入数据的形状。\n",
        "shape=(28*28,) 表示输入是一个 784 维的一维向量。\n",
        "为什么是 (28*28,)？\n",
        "MNIST 数据集中的图片是 28×28 的灰度图像。\n",
        "在 x_train = np.reshape(x_train, (60000, 28*28)) 这行代码中，我们将 28×28 的图片展平成 784 维的向量，所以 Input 层也要匹配这个形状\n",
        "\n",
        "\n",
        "Dense(10, activation='softmax') 定义了一个 全连接层（Dense 层），并使用 softmax 作为激活函数。\n",
        "参数解释\n",
        "10：表示该层的 神经元个数，即输出是一个 10 维向量。\n",
        "activation='softmax'：\n",
        "softmax 计算 10 个类别的概率分布，保证所有类别的概率加起来等于 1。\n",
        "适用于 多分类任务，如 MNIST（0~9，共 10 个类别）。\n",
        "计算过程\n",
        "如果 xin 传入的是一个 (60000, 784) 的数据：\n",
        "\n",
        "Dense(10) 作用：\n",
        "计算 权重矩阵 (W) 和 偏置 (b)：\n",
        "\n",
        "z=XW+b\n",
        "其中：\n",
        "X 是输入数据（形状：(batch_size, 784)）。\n",
        "W 是权重矩阵（形状：(784, 10)）。\n",
        "b 是偏置（形状：(10,)）。\n",
        "结果 z 形状是 (batch_size, 10)。\n",
        "\n",
        "softmax(z)：\n",
        "将 z 转换为概率分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBJtMj2pqJiR"
      },
      "source": [
        "xin = Input(shape=(28*28,))\n",
        "res = Dense(10,activation='softmax')(xin)\n",
        "\n",
        "mynet = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hXD5JT2ZrTJc",
        "outputId": "cff2783f-cd45-4833-e0c7-07425a557065"
      },
      "source": [
        "mynet.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m7,850\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjcOz8yrk5X"
      },
      "source": [
        "Now we need to compile the network.\n",
        "In order to do it, we need to pass two mandatory arguments:\n",
        "\n",
        "\n",
        "*   the **optimizer**, in charge of governing the details of the backpropagation algorithm\n",
        "*   the **loss function**\n",
        "\n",
        "Several predefined optimizers exist, and you should just choose your favourite one. A common choice is Adam, implementing an adaptive lerning rate, with momentum\n",
        "\n",
        "Optionally, we can specify additional metrics, mostly meant for monitoring the training process.\n",
        "mynet.compile() 用于配置模型的训练方式，定义：\n",
        "\n",
        "优化器 (optimizer)：决定如何更新权重参数，使损失最小化。\n",
        "损失函数 (loss)：衡量模型预测值和真实值之间的误差。\n",
        "评估指标 (metrics)：训练时显示的性能指标（如准确率）。\n",
        "\n",
        "Adam（Adaptive Moment Estimation）是最常用的深度学习优化器，它结合了：\n",
        "\n",
        "Momentum（动量）：让优化过程更平滑，防止震荡。\n",
        "RMSProp（自适应学习率）：自动调整每个参数的学习率，避免参数更新过大或过小。\n",
        "为什么选择 Adam？\n",
        "✅ 自动调整学习率，适用于大多数任务\n",
        "✅ 训练更快，比 SGD（随机梯度下降）收敛更快\n",
        "✅ 效果稳定，适用于各种深度学习任务（图像分类、NLP 等）\n",
        "\n",
        "替代方案\n",
        "\n",
        "optimizer='sgd'（随机梯度下降）：简单，但收敛速度慢。\n",
        "optimizer='rmsprop'（RMSProp）：适用于递归神经网络（RNN）。\n",
        "optimizer='adamax'：Adam 的变种，适用于非常稀疏的数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XK20mAFrrkQ"
      },
      "source": [
        "mynet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E58bT-Imvsw2"
      },
      "source": [
        "Finally, we fit the model over the trianing set.\n",
        "\n",
        "Fitting, just requires two arguments: training data e ground truth, that is x and y. Additionally we can specify epochs, batch_size, and many additional arguments.\n",
        "\n",
        "In particular, passing validation data allow the training procedure to measure loss and metrics on the validation set at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2woDXbbr6ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1d5981-a64d-48ec-ed32-c42ed44a1bd7"
      },
      "source": [
        "mynet.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.7262 - val_accuracy: 0.9144 - val_loss: 0.3078\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.3066 - val_accuracy: 0.9231 - val_loss: 0.2798\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2858 - val_accuracy: 0.9240 - val_loss: 0.2713\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2753 - val_accuracy: 0.9246 - val_loss: 0.2707\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2618 - val_accuracy: 0.9263 - val_loss: 0.2688\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2552 - val_accuracy: 0.9273 - val_loss: 0.2634\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2593 - val_accuracy: 0.9273 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.2614 - val_accuracy: 0.9255 - val_loss: 0.2659\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.2488 - val_accuracy: 0.9269 - val_loss: 0.2650\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.2457 - val_accuracy: 0.9269 - val_loss: 0.2635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5b226d1a90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0mBuorMulG5"
      },
      "source": [
        "xin = Input(shape=(784,))\n",
        "x = Dense(100,activation='relu')(xin)\n",
        "res = Dense(10,activation='softmax')(x)\n",
        "\n",
        "mynet2 = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpMyvw7buzhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1b13f8b2-8366-48ad-b1ab-30b101f4798f"
      },
      "source": [
        "mynet2.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYg0odW2u6cn"
      },
      "source": [
        "mynet2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDnzgIZVvGOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8ec507-98c5-408c-b43c-ac120b915f1e"
      },
      "source": [
        "mynet2.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.4353 - val_accuracy: 0.9619 - val_loss: 0.1323\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1238 - val_accuracy: 0.9719 - val_loss: 0.0939\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0793 - val_accuracy: 0.9680 - val_loss: 0.0995\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0615 - val_accuracy: 0.9763 - val_loss: 0.0769\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0437 - val_accuracy: 0.9774 - val_loss: 0.0754\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0338 - val_accuracy: 0.9765 - val_loss: 0.0823\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0265 - val_accuracy: 0.9772 - val_loss: 0.0758\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0215 - val_accuracy: 0.9782 - val_loss: 0.0752\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0164 - val_accuracy: 0.9755 - val_loss: 0.0870\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.9757 - val_loss: 0.0842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5b22653990>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcUKxCzKwzG9"
      },
      "source": [
        "An amazing improvement. WOW!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJr0EnAkw6nf"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1.   Add additional Dense layers and check the performance of the network\n",
        "2.   Replace 'relu' with different activation functions\n",
        "3. Adapt the network to work with the so called sparse_categorical_crossentropy\n",
        "4. the fit function return a history of training, with temporal sequences for all different metrics. Make a plot.\n",
        "\n"
      ]
    }
  ]
}