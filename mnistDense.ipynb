{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wSwJnsjx5P"
      },
      "source": [
        "# Mnist classification with NNs\n",
        "A first example of a simple Neural Network, applied to a well known dataset.from tensorflow.keras.layers import Input, Dense\n",
        "tensorflow.keras.layers\n",
        "The neural network layer modules provided by TensorFlow's Keras API:\n",
        "\n",
        "Input: Used to define the input layer of a neural network, specifying the shape of the input data.\n",
        "Dense: A fully connected (dense) layer, which is one of the most commonly used layers in neural networks where all neurons are interconnected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wMZ2Ge6jw1E"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDiNppLVkvqd"
      },
      "source": [
        "Let us load the mnist dataset\n",
        "\n",
        "tensorflow.keras.datasets: Common datasets provided by Keras.\n",
        "mnist: A handwritten digit recognition dataset consisting of grayscale images (28×28 pixels) classified into 10 categories (digits 0-9).\n",
        "Dataset Structure:\n",
        "x_train: Image data for the training set, with shape (60000, 28, 28), representing 60,000 grayscale images of size 28×28.\n",
        "\n",
        "y_train: Label data for the training set, with shape (60000,), representing 60,000 labels (each an integer from 0 to 9, indicating the digit class).\n",
        "\n",
        "x_test: Image data for the test set, with shape (10000, 28, 28), representing 10,000 grayscale images of size 28×28.\n",
        "\n",
        "y_test: Label data for the test set, with shape (10000,), representing 10,000 labels (each an integer from 0 to 9).\n",
        "\n",
        "x_train and x_test are 3D NumPy arrays with the format: (number of samples, height, width).\n",
        "\n",
        "y_train and y_test are 1D NumPy arrays with the format: (number of samples,), where each value is an integer between 0 and 9, representing the digit class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL8GyC0Nk14o"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijhDuLwwlQrI",
        "outputId": "e46f54d3-7f20-443e-b5d6-4d5c31c892d8"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(\"pixel range is [{},{}]\".format(np.min(x_train),np.max(x_train)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "pixel range is [0,255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01L64YcnWO5"
      },
      "source": [
        "[link text](https://)We normalize the input in the range [0,1]\n",
        "\n",
        "# Preprocessing MNIST Dataset for Deep Learning  \n",
        "\n",
        "## Normalize Pixel Values to [0, 1]  \n",
        "\n",
        "The pixel values in the MNIST dataset range from **0 to 255**, as it consists of grayscale images.  \n",
        "Using `astype('float32')` converts the data type, preventing precision loss due to integer operations.  \n",
        "\n",
        "### Why is this necessary?  \n",
        "\n",
        "1. **Deep learning models are sensitive to numerical ranges:**  \n",
        "   - Keeping pixel values in the range **0-255** may cause **large gradient variations**, affecting training stability.  \n",
        "   - Normalizing to **[0, 1]** makes it **easier for the model to learn**.  \n",
        "\n",
        "2. **Avoiding overflow issues:**  \n",
        "   - Deep learning involves extensive **matrix computations**, and without normalization, issues like **gradient explosion** or **vanishing gradients** may occur.  \n",
        "   - For example, computing `exp(x)` (as in the **softmax layer**) with excessively large input values can cause **numerical overflow**.  \n",
        "\n",
        "---\n",
        "\n",
        "## Convert 28×28 2D Image Data into a 1D Vector (784 Dimensions)  \n",
        "\n",
        "### Why is this necessary?  \n",
        "\n",
        "1. **Dense (fully connected) layers accept only 1D inputs:**  \n",
        "   - The **Dense layer** requires a **one-dimensional input vector**, but `x_train` originally has the shape **(60000, 28, 28) (3D)**.  \n",
        "   - Using `reshape(60000, 28*28)`, it transforms into **(60000, 784)**, converting each **28×28** ima\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8uA2Kp7mG9s"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = np.reshape(x_train,(60000,28*28))\n",
        "x_test = np.reshape(x_test,(10000,28*28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Layer Adaptation for Neural Networks (Softmax)  \n",
        "\n",
        "Using **Categorical Crossentropy Loss Function**  \n",
        "- Prevents integer labels from affecting learning performance  \n",
        "- Improves computational efficiency  \n",
        "\n",
        "## Why Use One-Hot Encoding?  \n",
        "\n",
        "### **Issue 1: Neural Networks May Misinterpret Integer Label Relationships**  \n",
        "If `y_train` is represented as integers (e.g., **0-9**), the model might **misinterpret the numerical relationships** between categories.  \n",
        "\n",
        "### **Issue 2: Softmax Output Layer Requires One-Hot Encoding**  \n",
        "Typically, the final layer of a classification model is a **softmax layer**, which outputs a **probability distribution** over the different categories.  \n",
        "\n",
        "### **Issue 3: Categorical Crossentropy Loss Requires One-Hot Encoding**  \n",
        "In classification tasks, we commonly use the **categorical crossentropy loss function (`categorical_crossentropy`)** to measure the difference between the predicted and true distributions.  \n",
        "\n",
        "---\n",
        "\n",
        "## **When Can We Skip One-Hot Encoding?**  \n",
        "\n",
        "If your output layer uses **`sparse_categorical_crossentropy`**, **One-Hot encoding is not needed**:  \n",
        "- This loss function works with **integer labels** (`y_train` remains in the range **0-9**).  \n",
        "- It is suitable for **large-category classification tasks** (e.g., **1000-class ImageNet**).  \n",
        "- However, in common classification tasks like **\n"
      ],
      "metadata": {
        "id": "Yjrzmhgh3TZv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzWUm0UnODb",
        "outputId": "ee0c71bb-108a-4327-974b-9280af4d0215"
      },
      "source": [
        "print(y_train[0])\n",
        "y_train_cat = utils.to_categorical(y_train)\n",
        "print(y_train_cat[0])\n",
        "y_test_cat = utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfeZF3bUrFZf"
      },
      "source": [
        "# Our First Network: Implementing Logistic Regression  \n",
        "\n",
        "## **Model Structure**  \n",
        "\n",
        "- `Input(shape=(784,))`: Defines the input tensor (Tensor).  \n",
        "- `Dense(64, activation='relu')(input_layer)`:  \n",
        "  - Creates weight matrix **W** and bias **b**.  \n",
        "  - Applies the **ReLU activation function**.  \n",
        "- `Model(inputs, outputs)`: Combines these layers to form a complete computational graph.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Understanding the Input Layer**  \n",
        "\n",
        "- **`Input()`**: Defines the input layer, specifying the shape of the input data.  \n",
        "- **`shape=(28*28,)`**: Represents a **784-dimensional vector**.  \n",
        "\n",
        "### **Why is the shape `(28*28,)`?**  \n",
        "- The **MNIST dataset** consists of **28×28 grayscale images**.  \n",
        "- In `x_train = np.reshape(x_train, (60000, 28*28))`, each **28×28** image is **flattened** into a **784-dimensional vector**.  \n",
        "- The `Input` layer must match this shape to process the input correctly.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Output Layer: Dense(10, activation='softmax')**  \n",
        "\n",
        "Defines a **fully connected layer (Dense layer)** with **softmax activation**.  \n",
        "\n",
        "### **Parameter Explanation:**  \n",
        "- **`10`**: Number of neurons, meaning the output is a **10-dimensional vector**.  \n",
        "- **`activation='softmax'`**:  \n",
        "  - Computes the **probability distribution** over **10 categories**.  \n",
        "  - Ensures that the sum of probabilities equals **1**.  \n",
        "  - Suitable for **multi-class classification tasks** like MNIST (**digits 0-9**).  \n",
        "\n",
        "---\n",
        "\n",
        "## **Computation Process**  \n",
        "\n",
        "### **Step 1: Dense(10) Computation**  \n",
        "Calculates the **weight matrix (W)** and **bias (b)**:  \n",
        "\n",
        "\\[\n",
        "z = XW + b\n",
        "\\]\n",
        "\n",
        "- **X**: Input data (**shape: `(batch_size, 784)`**).  \n",
        "- **W**: Weight matrix (**shape: `(784, 10)`**).  \n",
        "- **b**: Bias vector (**shape: `(10,)`**).  \n",
        "- The result **z** has shape **`(batch_size, 10)`**.  \n",
        "\n",
        "### **Step 2: Softmax(z)**\n",
        "Converts **z** into a **probability distribution**:\n",
        "\n",
        "\\[\n",
        "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{10} e^{z_j}}\n",
        "\\]\n",
        "\n",
        "Ensuring that the final output is a **vector of probabilities** for each class.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBJtMj2pqJiR"
      },
      "source": [
        "xin = Input(shape=(28*28,))\n",
        "res = Dense(10,activation='softmax')(xin)\n",
        "\n",
        "mynet = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hXD5JT2ZrTJc",
        "outputId": "cff2783f-cd45-4833-e0c7-07425a557065"
      },
      "source": [
        "mynet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m7,850\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjcOz8yrk5X"
      },
      "source": [
        "Now we need to compile the network.\n",
        "In order to do it, we need to pass two mandatory arguments:\n",
        "\n",
        "\n",
        "*   the **optimizer**, in charge of governing the details of the backpropagation algorithm\n",
        "*   the **loss function**\n",
        "\n",
        "Several predefined optimizers exist, and you should just choose your favourite one. A common choice is Adam, implementing an adaptive lerning rate, with momentum\n",
        "\n",
        "# Configuring Model Training with `mynet.compile()`  \n",
        "\n",
        "## **What Does `compile()` Do?**  \n",
        "The `mynet.compile()` function is used to configure how the model will be trained. It defines:  \n",
        "\n",
        "- **Optimizer (`optimizer`)**: Determines how weight parameters are updated to minimize loss.  \n",
        "- **Loss Function (`loss`)**: Measures the error between predictions and true values.  \n",
        "- **Evaluation Metrics (`metrics`)**: Performance indicators displayed during training (e.g., accuracy).  \n",
        "\n",
        "---\n",
        "\n",
        "## **Why Use Adam (Adaptive Moment Estimation)?**  \n",
        "\n",
        "Adam is one of the most commonly used **deep learning optimizers**, combining:  \n",
        "\n",
        "1. **Momentum**:  \n",
        "   - Helps smooth the optimization process.  \n",
        "   - Prevents oscillations in weight updates.  \n",
        "\n",
        "2. **RMSProp (Adaptive Learning Rate)**:  \n",
        "   - Automatically adjusts the learning rate for each parameter.  \n",
        "   - Prevents updates from being too large or too small.  \n",
        "\n",
        "### **Advantages of Adam:**  \n",
        "✅ **Adaptive learning rate**: Works well for most tasks.  \n",
        "✅ **Faster training**: Converges faster than SGD (Stochastic Gradient Descent).  \n",
        "✅ **Stable performance**: Suitable for various deep learning tasks (e.g., **image classification, NLP**).  \n",
        "\n",
        "---\n",
        "\n",
        "## **Alternative Optimizers**  \n",
        "\n",
        "- **`optimizer='sgd'` (Stochastic Gradient Descent)**:  \n",
        "  - Simple but slow convergence.  \n",
        "- **`optimizer='rmsprop'`**:  \n",
        "  - Suitable for **recurrent neural networks (RNNs)**.  \n",
        "- **`optimizer='adamax'`**:  \n",
        "  - A variant of Adam, ideal for **very sparse data**.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XK20mAFrrkQ"
      },
      "source": [
        "mynet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E58bT-Imvsw2"
      },
      "source": [
        "Finally, we fit the model over the trianing set.\n",
        "\n",
        "Fitting, just requires two arguments: training data e ground truth, that is x and y. Additionally we can specify epochs, batch_size, and many additional arguments.\n",
        "\n",
        "In particular, passing validation data allow the training procedure to measure loss and metrics on the validation set at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2woDXbbr6ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1d5981-a64d-48ec-ed32-c42ed44a1bd7"
      },
      "source": [
        "mynet.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.7262 - val_accuracy: 0.9144 - val_loss: 0.3078\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.3066 - val_accuracy: 0.9231 - val_loss: 0.2798\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2858 - val_accuracy: 0.9240 - val_loss: 0.2713\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2753 - val_accuracy: 0.9246 - val_loss: 0.2707\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2618 - val_accuracy: 0.9263 - val_loss: 0.2688\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2552 - val_accuracy: 0.9273 - val_loss: 0.2634\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2593 - val_accuracy: 0.9273 - val_loss: 0.2642\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.2614 - val_accuracy: 0.9255 - val_loss: 0.2659\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.2488 - val_accuracy: 0.9269 - val_loss: 0.2650\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.2457 - val_accuracy: 0.9269 - val_loss: 0.2635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5b226d1a90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0mBuorMulG5"
      },
      "source": [
        "xin = Input(shape=(784,))\n",
        "x = Dense(100,activation='relu')(xin)\n",
        "res = Dense(10,activation='softmax')(x)\n",
        "\n",
        "mynet2 = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpMyvw7buzhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1b13f8b2-8366-48ad-b1ab-30b101f4798f"
      },
      "source": [
        "mynet2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYg0odW2u6cn"
      },
      "source": [
        "mynet2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDnzgIZVvGOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8ec507-98c5-408c-b43c-ac120b915f1e"
      },
      "source": [
        "mynet2.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.4353 - val_accuracy: 0.9619 - val_loss: 0.1323\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1238 - val_accuracy: 0.9719 - val_loss: 0.0939\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0793 - val_accuracy: 0.9680 - val_loss: 0.0995\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0615 - val_accuracy: 0.9763 - val_loss: 0.0769\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0437 - val_accuracy: 0.9774 - val_loss: 0.0754\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0338 - val_accuracy: 0.9765 - val_loss: 0.0823\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0265 - val_accuracy: 0.9772 - val_loss: 0.0758\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0215 - val_accuracy: 0.9782 - val_loss: 0.0752\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0164 - val_accuracy: 0.9755 - val_loss: 0.0870\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.9757 - val_loss: 0.0842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5b22653990>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcUKxCzKwzG9"
      },
      "source": [
        "An amazing improvement. WOW!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJr0EnAkw6nf"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1.   Add additional Dense layers and check the performance of the network\n",
        "2.   Replace 'relu' with different activation functions\n",
        "3. Adapt the network to work with the so called sparse_categorical_crossentropy\n",
        "4. the fit function return a history of training, with temporal sequences for all different metrics. Make a plot.\n",
        "\n"
      ]
    }
  ]
}